原文链接：http://www.cnblogs.com/codingbigdog/archive/2022/05/07/16243279.html
提交日期：Sat, 07 May 2022 09:05:00 GMT
博文内容：
# 元学习
https://zhuanlan.zhihu.com/p/136975128
李宏毅元学习


# Cosine Normalization: Using Cosine Similarity Instead of Dot Product in Neural Networks
激活函数的输入是前一层的输出和权重的点积。由于点积没有大小限制，所以方差可能太大。而大的方差会对输入的分布比较敏感，这会导致泛化性变差和减慢训练速度。
我们提出了 cosine normalization， cosine normalization使用cosine similarity 或 centered cosine similarity来代替点积。
# Dynamic Few-Shot Visual Learning without Forgetting
在不忘记以前所学类的基础上学会识别更多的类，
To achieve that goal we propose (a) to extend an object recognition system withan attention based few-shot classification weight generator,and (b) to redesign the classifier of a ConvNet model as the cosine similarity function between feature representations
and classification weight vectors. 